{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_table(\"./sms.tsv\", header=None, names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms[\"label\"] = sms.label.map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13406317300789664"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sms.message\n",
    "y = sms.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All three methods of classification (LogisticRegression, DecisionTreeClasifier, NaiveBayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train, y_test, y_train = train_test_split(X,y, test_size=1000,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizing', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "   ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'standarization__with_mean': [False], 'logreg__C': [10, 1, 0.1, 0.01], 'logreg__penalty': ['l1', 'l2'], 'vectorizing__max_df': [1.0, 0.9], 'vectorizing__max_features': [3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_logreg = Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"standarization\",StandardScaler()),\n",
    "    (\"logreg\",LogisticRegression())])\n",
    "\n",
    "param_grid_logreg = {\"vectorizing__max_df\":[0.01,0.05],\n",
    "              \"vectorizing__max_features\":[3000],\n",
    "              \"vectorizing__max_df\":[1.0,0.9],\n",
    "              \"standarization__with_mean\":[False],\n",
    "              \"logreg__penalty\":[\"l1\",\"l2\"],\n",
    "              \"logreg__C\":[10,1,0.1,0.01]}\n",
    "\n",
    "gs = GridSearchCV(pipe_logreg, param_grid_logreg, cv = 5)\n",
    "\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590988626421697"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1,\n",
       " 'logreg__penalty': 'l1',\n",
       " 'standarization__with_mean': False,\n",
       " 'vectorizing__max_df': 1.0,\n",
       " 'vectorizing__max_features': 3000}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClasifier Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizing', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "   ...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tree__max_depth': [3, 5, 7, 10], 'tree__min_samples_leaf': [3, 5, 10, 15], 'vectorizing__max_df': [1.0, 0.9], 'vectorizing__max_features': [3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tree = Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"tree\",DecisionTreeClassifier())])\n",
    "param_grid_tree = {\"vectorizing__max_df\":[0.01,0.05],\n",
    "                   \"vectorizing__max_features\":[3000],\n",
    "                   \"vectorizing__max_df\":[1.0,0.9],\n",
    "                   \"tree__max_depth\":[3,5,7,10],\n",
    "                   \"tree__min_samples_leaf\":[3,5,10,15]}\n",
    "\n",
    "gs = GridSearchCV(pipe_tree,param_grid_tree, cv = 5)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tree__max_depth': 7,\n",
       " 'tree__min_samples_leaf': 5,\n",
       " 'vectorizing__max_df': 0.9,\n",
       " 'vectorizing__max_features': 3000}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vectorizing', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), pr...zer=None, vocabulary=None)), ('bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vectorizing__max_df': [1.0, 0.9], 'vectorizing__max_features': [3000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_bayes = Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"bayes\",MultinomialNB())])\n",
    "\n",
    "param_grid_bayes = {\"vectorizing__max_df\":[0.01,0.05],\n",
    "              \"vectorizing__max_features\":[3000],\n",
    "              \"vectorizing__max_df\":[1.0,0.9]}\n",
    "\n",
    "gs = GridSearchCV(pipe_bayes, param_grid_bayes, cv = 5)\n",
    "\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976159230096238"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs.best_estimator_.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizing__max_df': 1.0, 'vectorizing__max_features': 3000}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = {\n",
    "    \"logreg\": Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"standarization\",StandardScaler()),\n",
    "    (\"logreg\",LogisticRegression())])\n",
    "    ,\n",
    "    \"tree\":Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"tree\",DecisionTreeClassifier())])\n",
    "    ,\n",
    "    \"bayes\":Pipeline([\n",
    "    (\"vectorizing\",CountVectorizer()),\n",
    "    (\"bayes\",MultinomialNB())])\n",
    "   \n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"logreg\":{\"vectorizing__min_df\":[0.01,0.05],\n",
    "              \"vectorizing__max_features\":[3000],\n",
    "              \"vectorizing__max_df\":[1.0,0.9],\n",
    "              \"standarization__with_mean\":[False],\n",
    "              \"logreg__penalty\":[\"l1\",\"l2\"],\n",
    "              \"logreg__C\":[10,1,0.1,0.01]}\n",
    "    ,\n",
    "    \"tree\":{\"vectorizing__min_df\":[0.01,0.05],\n",
    "                   \"vectorizing__max_features\":[3000],\n",
    "                   \"vectorizing__max_df\":[1.0,0.9],\n",
    "                   \"tree__max_depth\":[3,5,7,10],\n",
    "                   \"tree__min_samples_leaf\":[3,5,10,15]}\n",
    "    ,\n",
    "    \"bayes\":{\"vectorizing__min_df\":[0.01,0.05],\n",
    "              \"vectorizing__max_features\":[3000],\n",
    "              \"vectorizing__max_df\":[1.0,0.9],\n",
    "              \"bayes__alpha\":[3000],\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [pipes, param_grids]\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in steps[0]:\n",
    "    pipe = steps[0][key]\n",
    "    param_grid = steps[1][key]\n",
    "    gs = GridSearchCV(pipe, param_grid, cv = 5)\n",
    "    gs.fit(X_train,y_train)\n",
    "    accuracy = accuracy_score(gs.best_estimator_.predict(X_test),y_test)\n",
    "    best_params = gs.best_params_\n",
    "    results[key] = {\"accuracy\":accuracy,\"best_params\":best_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tree\": {\n",
      "        \"best_params\": {\n",
      "            \"tree__max_depth\": 10, \n",
      "            \"vectorizing__max_features\": 3000, \n",
      "            \"vectorizing__min_df\": 0.01, \n",
      "            \"vectorizing__max_df\": 1.0, \n",
      "            \"tree__min_samples_leaf\": 3\n",
      "        }, \n",
      "        \"accuracy\": 0.941819772528434\n",
      "    }, \n",
      "    \"bayes\": {\n",
      "        \"best_params\": {\n",
      "            \"vectorizing__min_df\": 0.01, \n",
      "            \"vectorizing__max_df\": 1.0, \n",
      "            \"vectorizing__max_features\": 3000\n",
      "        }, \n",
      "        \"accuracy\": 0.9717847769028871\n",
      "    }, \n",
      "    \"logreg\": {\n",
      "        \"best_params\": {\n",
      "            \"standarization__with_mean\": false, \n",
      "            \"vectorizing__min_df\": 0.01, \n",
      "            \"logreg__penalty\": \"l2\", \n",
      "            \"logreg__C\": 0.01, \n",
      "            \"vectorizing__max_df\": 1.0, \n",
      "            \"vectorizing__max_features\": 3000\n",
      "        }, \n",
      "        \"accuracy\": 0.9698162729658792\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
